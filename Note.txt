딥러닝 네트워크에서는 노드에 들어오는 값들에 대해 곧바로 다음 레이어로 전달하지 않고 주로 비선형 함수를 통과시킨 후 전달한다.
 이때 사용하는 함수를 활성화 함수(Activation Function) 이라 부른다.

공분산 : 2개의 확률 변수의 상관정도를 나타내는 값이다.

PCA : 단순히 압축한다. ? 알집을 압축하는 것 처럼 예를 들어 50개의 칼럼이 있다면 그것을 가장 적절한 개수로 압축한다. 
      그 적절한 개수는 전혀다른 새로운 칼럼? 말이 됨? 

---------------------파일명-----------------
              dnn     lstm    cnn
iris           76,     77,    78 아이리스 꽃  
diabets?       79,     80,    81 당뇨병
brest cancer?  82,     83,    84 유방암



pd.get_dummies()

넘파이,판다스 공부하기

엄청나게 잘 정제된 데이터일 수록 레이어와 노드의 갯수가 꼭 많을 필요는 없다 

softmax 의 총 값은 1로 나오고 그중 가장 높은값을 argmax로 선택

earlystopping의 단점 -> 이미 과적합이 지나고 있는 부분이므로 시점만 파악하고 수동으로 튜닝한다

모델 저장하는 방법 

load_weight 뭐야 이거 -> 해결

가중치를 저장할 수 있는방법 3가지 modelcheckpoint, model.save(), model.save_weight()

예제 10가지에 대한 3가지 모델중 가장 최적화된 모델의 model.save, model.save_weight, modelcheckpoint

비선형 활성화함수 relu, sigmoid

backpropagation : 오차 역전파 
Vanishing Gradient Problem : 기울기 소실 문제
optimaizer : 반복 최적화 알고리즘 

'''
반복횟수에 맞는 적당한 레이어의 갯수가 필요하다? 
가중치가 너무 작은 값이면 가중치가 충분히 변화하지 않기 때문에 최적에 도달하기위해 많은 반복횟수를 요구하게되고 
너무큰 가중치는
'''

확장자가 .npy 로 저장하는 방법
csv파일 불러서 .npy

넘파이에서는 헤더까지 불러오면 에러가 난다
csv파일을 불러오고 첫행과 첫열을 사용할지 말지 판단해야함 

csv파일을 받아서 numpy로 저장해서 모델링하고 model.save를 이용해서 

hite = hite.fillna(method='bfill') -> nan에 전에 있던 값을 넣는다
hite = hite.fillna(method='ffill') -> nan에 이후에 있는 값을 넣는다

hite.loc['2020-06-02', '고가': '거래량'] = ['10','20','30','40']

타임 스텝스를 바꾸면 2일치의 예측 값이 나온다? -> 질문 

헤더가 2줄이라면 header = 1로 해서 0~1까지 헤더라고 인식시켜줘면된다 

iloc는 헤더와 인덱스 인덱스 번호를 이용
loc는 헤더와 인덱스의 이름을 이용

nan값은 부동소수점으로 인식됨 

cnn은 특성을 짤라서 한다 -> 나중에 시계열을 cnn으로 모델링하기 
lstm

앙상블할때 삼성을 2개의 모델과 하이트 진로의 모델 1개를 넣으면 삼성 쪽으로 가중치의 비중이 많아진다?



sklearn LinearSVC에 대해 알아보자 

회기일때 r2와 그냥 스코어 같은지 보고
분류일때 스코어와 에큐러시가 같은지 확인
그래서? 어떨때 어떤 모델을 쓸것인가에 대해 생각해보자

레거시한 머신러닝을 이용하여 결측치와 이상치를 채워준다 

LinearLogisticRegressor는 분류모델링 할때 주로 사용하는 것이지 회기 모델링을 할때 사용하는 오류를 범하지 말자
model.score는 자동으로 적당한 지표를 골라 계산하고 알려준다
회기에서 RandomForestRegressor로 모델링할때 지표를 acc로 잡는 실수를 범하지 말자 

SVC와 LinearSVC와의 차이점을 알아보자

그리드 서치 p.389 -> 내가 넣은 조건을 빠짐없이 테스트 해본다 -> 좋지만은 않음 -> 랜덤 서치

자동으로 복수개의 내부 모형을 생성하고 이를 모두 실행시켜서 최적 파라미터를 찾아준다.

그리드 서치와 랜더마이즈드 서치의 파라미터를 확인하고 비교해보기 

*****책이나 인터넷에서 그날그날 배운내용 찾아보기*****

0608
머신러닝에서는 원핫인코딩을 하지않아도 상관없다 
kfold에서 cv(crossvalidation)값에 따라서 데이터를 n등분

y값에 대한 결측치를 채워주는 판다의 기능이 있음 

선형에 잘맞는 PCA ??
featureimportance

파이프라인 -> 완전한 오토 하이퍼 파라미터튜닝

제너레이터를 이용하면 이미지를 수치화 할 수 있음?

conv1D

전처리 자동화 까지 minmax,standard -> pipeline
전처리 친구는 파이프라인 

x값 groupby 하기

0610
decision tree
feature importance

트리구조의 장점은 전처리가 필요없다 
2가지 장점이 있음 

내가 depth를 4에서 3으로 했을때 테스트 값에 대한 스코어값 

아이디어 
구현기술
계획수립
일정
최종결과 예측